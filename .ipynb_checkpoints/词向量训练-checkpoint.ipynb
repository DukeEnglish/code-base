{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "英文预训练词向量很不错,  https://nlp.stanford.edu/projects/glove/\n",
    "    使用时首行加入一行行数和向量维度, gensim即可调用."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sed -i '1i 400000 300' glove.6b.300d.txt\n",
    "\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format('glove.6b.300d.txt', binary=False)\n",
    "\n",
    "# 获取最相似\n",
    "for w, s in model.most_similar('apple', topn=5):\n",
    "    print w, s\n",
    "\n",
    "# 获取向量\n",
    "print model['apple']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "构建中文语料库, 下载推荐: http://www.sogou.com/labs/resource/list_news.php\n",
    "        \n",
    "里面用到了切词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 搜狐新闻 2.1G\n",
    "tar -zxvf news_sohusite_xml.full.tar.gz \n",
    "cat news_sohusite_xml.full.tar.gz | iconv -f gb18030 -t utf-8 | grep \"<content>\" > news_sohusite.txt\n",
    "sed -i 's/<content>//g' news_sohusite.txt\n",
    "sed -i 's/<\\/content>//g' news_sohusite.txt\n",
    "python -m jieba -d ' ' news_sohusite.txt > news_sohusite_cutword.txt\n",
    "\n",
    "# 全网新闻 1.8G\n",
    "tar -zxvf news_tensites_xml.full.tar.gz \n",
    "cat news_tensites_xml.full.tar.gz | iconv -f gb18030 -t utf-8 | grep \"<content>\" > news_tensite.txt\n",
    "sed -i 's/<content>//g' news_tensite.txt\n",
    "sed -i 's/<\\/content>//g' news_tensite.txt\n",
    "python -m jieba -d ' ' news_tensite.txt > news_tensite_cutword.txt\n",
    "\n",
    "# 其它自身的结合业务需要的预料, 如公司简介\n",
    "python -m jieba -d ' ' other_entdesc.txt > other_entdesc_cutword.txt\n",
    "\n",
    "# 合并切割好的语料\n",
    "cat news_sohusite_cutword.txt news_tensite_cutword.txt other_entdesc_cutword.txt > w2v_chisim_corpus.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models.word2vec import LineSentence\n",
    "\n",
    "sentences = LineSentence('w2v_chisim_corpus.txt')\n",
    "model = Word2Vec(sentences, size=300, window=8, min_count=10, sg=1, workers=4)  # sg=0 使用cbow训练, sg=1对低频词较为敏感\n",
    "model.save('w2v_chisim.300d.txt')\n",
    "\n",
    "\n",
    "for w, s in model.most_similar(u'苹果'):\n",
    "    print w, s\n",
    "\n",
    "for w, s in model.most_similar(u'中国'):\n",
    "    print w, s\n",
    "\n",
    "for w, s in model.most_similar(u'中山大学'):\n",
    "    print w, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
